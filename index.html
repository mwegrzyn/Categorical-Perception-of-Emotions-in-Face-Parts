<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Categorical-perception-of-emotions-in-face-parts : Manuscript, Code and Data of the manuscript &quot;Categorical Perception of Fear and Anger Expressions in Whole, Masked and Composite Faces&quot;, DOI: 10.1371/journal.pone.0134790 ">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Categorical-perception-of-emotions-in-face-parts</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/mwegrzyn/Categorical-Perception-of-Emotions-in-Face-Parts">View on GitHub</a>

          <h1 id="project_title">Categorical-perception-of-emotions-in-face-parts</h1>
          <h2 id="project_tagline">Manuscript, Code and Data of the manuscript &quot;Categorical Perception of Fear and Anger Expressions in Whole, Masked and Composite Faces&quot;, DOI: 10.1371/journal.pone.0134790 </h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/mwegrzyn/Categorical-Perception-of-Emotions-in-Face-Parts/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/mwegrzyn/Categorical-Perception-of-Emotions-in-Face-Parts/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>
<a id="categorical-perception-of-fear-and-anger-expressions-in-whole-masked-and-composite-faces" class="anchor" href="#categorical-perception-of-fear-and-anger-expressions-in-whole-masked-and-composite-faces" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Categorical Perception of Fear and Anger Expressions in Whole, Masked and Composite Faces</h1>

<p>Martin Wegrzyn, Isabelle Bruckhaus &amp; Johanna Kissler  </p>

<p>Published: August 11, 2015<br>
<a href="http://dx.doi.org/10.1371/journal.pone.0134790">DOI: 10.1371/journal.pone.0134790</a></p>

<h3>
<a id="abstract" class="anchor" href="#abstract" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Abstract</h3>

<p>Human observers are remarkably proficient at recognizing expressions of emotions and at readily grouping them into distinct categories. When morphing one facial expression into another, the linear changes in low-level features are insufficient to describe the changes in perception, which instead follow an s-shaped function. Important questions are, whether there are single diagnostic regions in the face that drive categorical perception for certain parings of emotion expressions, and how information in those regions interacts when presented together.
We report results from two experiments with morphed fear-anger expressions, where (a) half of the face was masked or (b) composite faces made up of different expressions were presented. When isolated upper and lower halves of faces were shown, the eyes were found to
be almost as diagnostic as the whole face, with the response function showing a steep category boundary. In contrast, the mouth allowed for a substantially lesser amount of accuracy and responses followed a much flatter psychometric function. When a composite face consisting of mismatched upper and lower halves was used and observers were instructed to exclusively judge either the expression of mouth or eyes, the to-be-ignored part always influenced perception of the target region. In line with experiment 1, the eye region exerted a much stronger influence on mouth judgements than vice versa. Again, categorical perception was significantly more pronounced for upper halves of faces. The present study shows that identification of fear and anger in morphed faces relies heavily on information from the upper half of the face, most likely the eye region. Categorical perception is possible when only the upper face half is present, but compromised when only the lower part is shown. Moreover, observers tend to integrate all available features of a face, even when trying to focus on only one part.</p>

<h3>
<a id="about" class="anchor" href="#about" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>About</h3>

<p>This is a repository containting the full data and code of our <a href="http://dx.doi.org/10.1371/journal.pone.0134790">PLOS paper</a> about morphed facial expressions.  </p>

<p>For the present repository, I have added this readme and also changed the folder structure a bit, so that there are slight amendments to the code, but only and solely when it comes to folder access routines and folder names. These changes were made to provide the highest possible convenience for anyone trying the re-run the analyses. Once you have the python modules needed, everything should run as-is, if you just download the whole repository.<br>
All original code and data can still be found as a supplement to the PLOS paper.  </p>

<p>Also, I have added files to document the whole submission/resubmission process of the paper, for the sake of full transparency (cf. 'submissions' folder).  </p>

<p>Finally, you will find the experiment files for all participants. These require the (non-free) software 'Presentation' to run. Also, the stimuli folder is missing, as I cannot upload the images used due to copyright restrictions. Please contact me if you would like to obtain them. One you paste the images into the respective folder, you should be able to re-run the experiments. The instructions for participants are in German though. Ask me if you need a translation.</p>

<h3>
<a id="table-of-contents" class="anchor" href="#table-of-contents" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Table of Contents</h3>

<ul>
<li><a href="journal_pone_0134790.pdf">the published manuscript</a></li>
<li>the code

<ul>
<li><a href="S1_Code_Experiment1_Data_Import.ipynb">Data Import for Experiment 1</a></li>
<li><a href="S2_Code_Experiment2_Data_Import.ipynb">Data Import for Experiment 2</a></li>
<li><a href="S3_Code_MainResults.ipynb">Main Results</a></li>
<li><a href="S4_Code_CurveFitting.ipynb">Curve Fitting</a></li>
<li><a href="S5_Code_CrossValidation.ipynb">Cross-Validation</a></li>
<li><a href="S6_Code_AdditionalIdentityAnalyses.ipynb">Analyses by Face Identity</a></li>
<li><a href="my_plots.py">some functions for easier plotting</a></li>
</ul>
</li>
<li><a href="experiment/">the experiment files</a></li>
<li><a href="data/">the participant logfiles + outputs of my analyses</a></li>
<li><a href="submissions/">the original submissions</a></li>
</ul>

<h3>
<a id="requirements" class="anchor" href="#requirements" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Requirements</h3>

<p>Data analysis was performed with Python 2.7.9 <a href="http://www.python.org">www.python.org</a> using mainly NumPy, SciPy, Pandas, Matplotlib, Seaborn and the IPython Notebook/Jupyter, all as provided with Anaconda 2.2.0 (Continuum Analytics; <a href="http://docs.continuum.io/anaconda">docs.continuum.io/anaconda</a>).</p>

<h3>
<a id="contact" class="anchor" href="#contact" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contact</h3>

<p>For questions or comments please write to <a href="mailto:martin.wegrzyn@uni-bielefeld.de">martin.wegrzyn@uni-bielefeld.de</a>  </p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Categorical-perception-of-emotions-in-face-parts maintained by <a href="https://github.com/mwegrzyn">mwegrzyn</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
